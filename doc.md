# Predict Defective Commits Just-In-Time

## Introduction

Le d√©veloppement logiciel moderne, particuli√®rement en environnement collaboratif, est caract√©ris√© par des changements fr√©quents et rapides du code source. Chaque modification (ou commit) introduite dans le code peut potentiellement provoquer des erreurs ou des r√©gressions, compromettant la stabilit√© et la fiabilit√© du logiciel. Pour r√©pondre √† ce d√©fi, ce projet propose de d√©velopper une intelligence artificielle pr√©dictive capable de d√©terminer l'impact d'un commit sur le reste du code et d'estimer la probabilit√© de r√©gression.

L'objectif de cette √©tude est d'examiner les approches existantes pour la pr√©diction des commits d√©fectueux et de proposer une solution innovante qui s'appuie sur les techniques avanc√©es de machine learning et de deep learning. Cette solution permettra d'identifier proactivement les commits susceptibles de causer des probl√®mes, offrant ainsi aux d√©veloppeurs des outils pour am√©liorer la qualit√© du code et r√©duire les co√ªts associ√©s aux erreurs et aux r√©gressions.

## Predict Defective Commits Just-In-Time

### A. Logistic Regression

### B. Deeper: Feature selection phase + Classification phase

### Just-In-Time defective prediction

![alt text](image-7.png)

1. Label commits as buggy or not according to history.
2. Extract from each commit its features‚Äô values.
3. The labeled commits + corresponding features are fed to classification algorithm.
4. New commit ‚áí Feature values extraction ‚áí fed to the learned model ‚áí Buggy / Not.

### A. Logistic Regression Cons

- Cannot create combined features.
- Selection of only input features that are linear to output labels.
  - Bad training performance / training failure.

‚áí Here comes Deeperüéâ

### B. Deeper‚Äôs Pros

- Generation of more expressive feature set from initial one. ‚áí More efficient and precise in expressing the nature of a problem.
- It can create combined features.

Deeper = DL + ML ‚áí Predict if commits are defected or not.

1. Feature selection: Select from commit features the most expressive features using Deep Belief Network Algorithm.
2. ML: Selected features are fed to ML predictive classifier.

- For evaluation, we used datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 commits.
![alt text](image-6.png)
## Evaluation

| Approach        | Discovered Bugs | F1-Score  |
|-----------------|-----------------|-----------|
| Kamei et al (LR)| 18.82%          | 0.22-0.63 |
| Deeper          | 51.04%          |           |

The comparison of the approach with the approach proposed by Kamei et al. showed that on average across the 6 projects, Deeper could discover 32.22% more bugs than Kamei et al‚Äôs approach (51.04% versus 18.82% on average). In addition, Deeper can achieve F1 scores of 0.22-0.63, which are statistically significantly higher than those of Kamei et al.‚Äôs approach on 4 out of the 6 projects.

### Cons

The approach does not leverage the true notions of deep learning as they still employ the same set of features that are manually engineered as in previous work, and their model is not end-to-end trainable.

## Graph-based Machine Learning Improves Just-In-Time Defect Prediction

### Proposed Method

The research introduces a novel framework for Just-In-Time (JIT) defect prediction by utilizing graph-based machine learning (ML) on contribution graphs. These graphs represent the interactions between developers and source code files, aiming to improve the prediction of defect-prone changes in software development.

The purpose of this research is to improve the accuracy of predicting defect-prone code changes by leveraging graph-based ML techniques. The hypothesis is that features extracted from contribution graphs provide better predictive power than traditional software characteristic features.

### Phases

The method is composed of three main phases: dataset generation, training, and testing.

1. In the dataset generation phase, building a labeled commit dataset by combining the extracted graph features from the contribution graph and bug-inducing commits produced by the SZZ algorithm.
2. During the training phase, processing the training data by conducting data preparation, model training, and selection on a subset of classifiers.
3. During the testing phase, preparing the data from given code commits and feeding it into the trained model. Predictions from the classifiers are used to estimate the quality of the predictions.
![alt text](image-8.png)

### Performance Metrics

The performance of the proposed approach is measured using:

- **F1 Score**: The best model achieved an F1 score of 77.55%, which is 152% higher than the state-of-the-art.
- **Matthews Correlation Coefficient (MCC)**: The best model achieved an MCC of 53.16%, which is 3% higher than the state-of-the-art.

### Contributions

- **Graph-Based ML for JIT Defect Prediction**: This study introduces the use of graph-based ML techniques for JIT defect prediction, specifically through contribution graphs that model developer interactions with source files.
- **Edge Classification Framework**: The approach frames JIT defect prediction as an edge classification problem, assigning probability scores to new code changes to predict defect likelihood.
- **Feature Extraction and Evaluation**: Features are extracted from contribution graphs using centrality metrics and community assignments/node embeddings. These features are then used to inform ML models for classifying defect-prone changes.
- **Empirical Validation**: The research evaluates the graph-based ML models on 14 open-source projects, demonstrating significant improvements over traditional JIT defect prediction methods in terms of F1 score and MCC.

ML Models used: Logistic regression, Random forest, XG Boost

## Predicting Technical Debt from Commit Contents: Reproduction and Extension with Automated Feature Selection

### A. Study of Yan et al
![alt text](image-3.png)
### B. Extending the study of ‚ÄòYan et al‚Äô by replacing their manually chosen features with automated feature selection
![alt text](image-2.png)
https://link.springer.com/article/10.1007/s11219-020-09520-3
https://link.springer.com/article/10.1007/s11219-020-09520-3
https://link.springer.com/article/10.1007/s11219-020-09520-3

### Methodology
![alt text](image-9.png)
#### Step 1: Dataset creation

The dataset was created by collecting data from five open-source GitHub repositories and merging it with an existing dataset.

#### Step 2: Basic preprocessing

Basic preprocessing was applied to commit messages, including converting to lower case, removing hashes, stop words, developer names, special characters, and tokenizing the text to prepare it for analysis.

#### Step 3: Advanced preprocessing

Advanced preprocessing was conducted to improve word generalizability by imposing constraints on word appearances across repositories and using percentage thresholds to exclude rare and project-specific terms.

#### Step 4: Different NLP techniques, machine learning classifier, and statistical methods

Three NLP techniques were compared for SATD prediction accuracy using logistic regression, alongside a description of the machine learning classifier and statistical methods used for evaluating the results.

1. **NLP technique 1: Bag-of-words**: Represents each commit message as a collection of words and their frequencies, ignoring word order.
2. **NLP technique 2: Topic discovery**: Used to find topics within commit messages.
3. **NLP technique 3: Word embeddings**: Represents words as semantic vectors, allowing for the identification of similarities between words.
4. **Machine learning classifier**: A binomial logistic regression with lasso penalty is used for classification.
5. **Statistical analysis**: Statistical analysis is conducted to validate the results and determine the significance of predictor words in identifying SATD.

### Results

#### Comparison of three NLP techniques

| Model Name        | Median AUC |
|-------------------|-------------|
| Bag of Words      | 0.7411      |
| Word Embeddings   | 0.6631      |
| Topic Modeling    | 0.6294      |

- The Bag-of-words outperforms the other two techniques with a median AUC of 0.7411.

#### The performance of Yan et al.'s model compared to the new model with automatic selection of features
![alt text](image-10.png)
- Accepting the alternative hypothesis that automatically selected features improve performance over manually selected ones.

## Utilisation de l'historique de Validation Git pour la modification pr√©diction

### But du projet

- Enqu√™ter et √©valuer l'utilit√© de l'utilisation de l'historiques de modifications
- Pr√©dire et sugg√©rer les fichiers susceptibles d‚Äô√™tre modifi√©s ensemble
- Se concentrer sur Git ‚áí d√©terminer les avantages des contr√¥les des versions
gestion automatique des historiques et la r√©solution des erreurs
![alt text](image-11.png)![alt text](image-12.png)
### Rule Learning

- Trouver les ensembles des √©l√©ments fr√©quents
- Calculer les r√®gles d'association

### Utiliser Java

- **JGit**: Lire les donn√©es des d√©p√¥ts git
- **R**: Biblioth√®que des r√®gles d‚Äôassociation

### Parcours commit par commit

- Traiter les changements et les stocker dans une structure de donn√©es, ensuite appliquer R et ouvrir les feedbacks.
  - (+) √âvaluation des performances g√©n√©rales de pr√©diction
  - (+) Suivi automatique des renommages et analyse des commits de correction de bogues


![alt text](image-13.png)




![alt text](image-14.png)

![alt text](image-15.png)![alt text](image-16.png)![alt text](image-17.png)
![alt text](image-18.png)
![alt text](image-19.png)
## Articles

# Article 1: "Predicting Faults from Cached History" by Kim et al.

Ce article explore des mod√®les pr√©dictifs pour anticiper les d√©fauts logiciels en utilisant des donn√©es historiques. Voici une analyse :

## Mod√®les Utilis√©s

### Change Classification Model
Les auteurs utilisent un mod√®le de classification pour pr√©dire les changements susceptibles de contenir des d√©fauts dans le logiciel. Ce mod√®le utilise des caract√©ristiques telles que la complexit√© des changements, l'exp√©rience des d√©veloppeurs et l'historique des changements.

- **Naive Bayes Classifier** : Plus pr√©cis√©ment, ils utilisent un classificateur Naive Bayes pour traiter ces caract√©ristiques et pr√©dire la probabilit√© de d√©fauts dans les nouveaux changements.

## Avantages

- **Rappel √âlev√©** : Le mod√®le d√©montre un rappel √©lev√©, ce qui signifie qu'il identifie efficacement la plupart des changements susceptibles de contenir des d√©fauts, ce qui est crucial dans la maintenance logicielle.
- **Utilisation des Donn√©es Historiques** : En utilisant l'historique mis en cache, le mod√®le peut faire des pr√©dictions inform√©es bas√©es sur des sch√©mas pass√©s, am√©liorant ainsi la pr√©cision au fil du temps.

## Inconv√©nients

- **Compromis sur la Pr√©cision** : Bien que le rappel soit √©lev√©, la pr√©cision est plus faible, entra√Ænant de nombreux faux positifs. Cela signifie que bien que la plupart des d√©fauts soient captur√©s, de nombreux changements non d√©fectueux sont √©galement signal√©s, ce qui peut √™tre inefficace.
- **D√©pendance aux Donn√©es Historiques** : L'efficacit√© du mod√®le repose fortement sur la disponibilit√© et la qualit√© des donn√©es historiques. Dans les projets avec un historique rare ou bruit√©, la pr√©cision du mod√®le peut diminuer.

# Article 2: "Predictive Modeling: Revolutionizing Decision-Making with AI" by Simplilearn

Cet article fournit un aper√ßu de diverses techniques de mod√©lisation pr√©dictive et de leurs applications, en se concentrant sur des cas d'utilisation commerciale et technique, qui peuvent √™tre analogiquement appliqu√©s √† l'ing√©nierie logicielle.

## Mod√®les Utilis√©s

- **Regression Models** : Utilis√©s pour pr√©dire des r√©sultats num√©riques bas√©s sur des donn√©es historiques. Des exemples incluent la r√©gression lin√©aire et logistique.
- **Neural Networks** : Particuli√®rement utiles pour capturer des sch√©mas complexes dans de grands ensembles de donn√©es, les r√©seaux neuronaux tels que les CNN et RNN peuvent √™tre utilis√©s pour pr√©dire les d√©fauts logiciels en apprenant √† partir des donn√©es historiques de commits.
- **Ensemble Methods** : Les techniques comme le bagging et le boosting combinent plusieurs mod√®les pour am√©liorer la pr√©cision et la robustesse des pr√©dictions.

## Avantages

- **Polyvalence** : La gamme de mod√®les (r√©gression, r√©seaux neuronaux et m√©thodes d'ensemble) peut √™tre adapt√©e √† des t√¢ches de pr√©diction sp√©cifiques, telles que l'impact d'un commit ou la probabilit√© de r√©gression.
- **Am√©lioration de la Prise de D√©cision** : Les mod√®les pr√©dictifs fournissent des informations bas√©es sur les donn√©es, permettant une meilleure allocation des ressources et gestion des risques dans le d√©veloppement logiciel.
- **Pr√©cision Am√©lior√©e avec les M√©thodes d'Ensemble** : La combinaison de plusieurs mod√®les peut am√©liorer consid√©rablement la pr√©cision des pr√©dictions, rendant l'approche robuste contre les faiblesses des mod√®les individuels.

## Inconv√©nients

- **Qualit√© et Quantit√© des Donn√©es** : La pr√©cision des mod√®les pr√©dictifs d√©pend fortement de la qualit√© et de la quantit√© des donn√©es historiques. Des donn√©es insuffisantes ou de mauvaise qualit√© peuvent conduire √† des pr√©dictions peu fiables.
- **Surapprentissage** : Les mod√®les complexes, en particulier les r√©seaux neuronaux, sont sujets au surapprentissage, o√π ils performent bien sur les donn√©es d'entra√Ænement mais mal sur de nouvelles donn√©es non vues.
- **Interpr√©tabilit√©** : Les mod√®les avanc√©s, en particulier les r√©seaux neuronaux, peuvent √™tre difficiles √† interpr√©ter, ce qui rend difficile la compr√©hension des raisons pour lesquelles certaines pr√©dictions sont faites.
## Solution Propos√©e

La solution propos√©e repose sur une approche en deux phases : la phase de s√©lection des caract√©ristiques et la phase de classification.

### Phase 1 : S√©lection des Caract√©ristiques

La premi√®re √©tape consiste √† extraire et s√©lectionner les caract√©ristiques les plus pertinentes des commits. Cette phase utilise un r√©seau de croyance profonde (Deep Belief Network, DBN) pour identifier les attributs les plus expressifs des commits. Ces caract√©ristiques peuvent inclure, entre autres, des informations sur le code modifi√©, les m√©tadonn√©es du commit (comme l'auteur, la date, le message de commit), et des informations issues de l'historique des versions.

### Phase 2 : Classification

Une fois les caract√©ristiques s√©lectionn√©es, elles sont utilis√©es pour entra√Æner un mod√®le de classification. Ce mod√®le de machine learning est capable de pr√©dire si un nouveau commit est susceptible d'introduire un bug ou une r√©gression. Des algorithmes de classification comme la r√©gression logistique ou des techniques plus avanc√©es de deep learning sont utilis√©s pour cette t√¢che.

### Processus de Pr√©diction

1. **√âtiquetage des Commits** : Les commits sont d'abord √©tiquet√©s comme "bogu√©s" ou "non bogu√©s" en se basant sur les donn√©es historiques.
2. **Extraction des Caract√©ristiques** : Pour chaque commit, les valeurs des caract√©ristiques pertinentes sont extraites.
3. **Entra√Ænement du Mod√®le** : Les commits √©tiquet√©s et leurs caract√©ristiques sont utilis√©s pour entra√Æner le mod√®le de classification.
4. **Pr√©diction** : Lorsqu'un nouveau commit est soumis, ses caract√©ristiques sont extraites et pass√©es au mod√®le entra√Æn√©, qui pr√©dit alors si le commit est "bogu√©" ou "non bogu√©".

### Avantages de la Solution

- **D√©tection Proactive des Bugs** : En pr√©disant les commits d√©fectueux avant qu'ils ne soient int√©gr√©s au code principal, les d√©veloppeurs peuvent intervenir plus rapidement et r√©duire les r√©gressions.
- **Am√©lioration de la Qualit√© du Code** : Une analyse continue et automatique des commits permet de maintenir une haute qualit√© du code.
- **R√©duction des Co√ªts de Maintenance** : En identifiant les probl√®mes t√¥t, les co√ªts associ√©s √† la correction des bugs et des r√©gressions sont r√©duits.
